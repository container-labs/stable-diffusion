version: "3"

volumes:
  pip_cache:
  model_cache:
  conda_cache:

services:
  app:
    # force amd so it's the same as remote
    platform: linux/amd64
    build:
      context: ./docker/notebook
      dockerfile: Dockerfile
    # command: python3 main.py
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - XRT_TPU_CONFIG="localservice;0;localhost:51011"
    # mps not supported yet
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - capabilities: [gpu]
    # https://stackoverflow.com/questions/43844639/how-do-i-add-cached-or-delegated-into-a-docker-compose-yml-volumes-list
    volumes:
      - pip_cache:/root/.cache/pip:delegated
      # TODO: make this one sync w/ localhost
      - model_cache:/root/.cache/huggingface:delegated
      - ./image_dir:/image_dir:default

  base:
    platform: linux/amd64
    build:
      context: ./ml-base
      dockerfile: Dockerfile.base
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    volumes:
      - pip_cache:/root/.cache/pip:delegated
      # TODO: make this one sync w/ localhost
      - model_cache:/root/.cache/huggingface:delegated
      - ./image_dir:/image_dir:default
  training-base:
    platform: linux/amd64
    build:
      context: ./ml-base
      dockerfile: Dockerfile.training-base
      args:
        - BASE_IMAGE=stable-diffusion_base
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    volumes:
      - conda_cache:/root/.conda:delegated
      - pip_cache:/root/.cache/pip:delegated
      # TODO: make this one sync w/ localhost
      - model_cache:/root/.cache/huggingface:delegated
      - ./image_dir:/image_dir:default

  training:
    # force amd so it's the same as remote
    platform: linux/amd64
    build:
      context: ./docker/training
      dockerfile: Dockerfile
      args:
        - BASE_IMAGE=stable-diffusion_training-base
      # entrypoint:
      #   - ./train-style.sh
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    volumes:
      - conda_cache:/root/.conda:delegated
      - pip_cache:/root/.cache/pip:delegated
      - ./model-cache:/root/.cache/huggingface:default
      - ./image_dir:/image_dir:default

  train:
    build:
      context: ./py-jobs
    command: python train.py
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - GOOGLE_APPLICATION_CREDENTIALS=creds.json
      - GOOGLE_CLOUD_PROJECT=md-wbeebe-0808-example-apps
      - REGION=us-central1
      - GCS_BUCKET=gs://md-ml
      - GCP_TOPIC=training-requests
      - GCP_SUBSCRIPTION=trainer-sub

  orchestration:
    build:
      context: ./py-jobs
    command: python runner.py
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - GOOGLE_APPLICATION_CREDENTIALS=creds.json
      - GOOGLE_CLOUD_PROJECT=md-wbeebe-0808-example-apps
      - REGION=us-central1
      - GCS_BUCKET=gs://md-ml
      - GCP_TOPIC=training-requests
      - GCP_SUBSCRIPTION=trainer-sub
  # flow:
  #   build:
  #     context: ./flow
  #   command: python main.py
  #   environment:
  #     - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
  #     - GOOGLE_APPLICATION_CREDENTIALS=creds.json
  #     - GOOGLE_CLOUD_PROJECT=md-wbeebe-0808-example-apps
  #     - REGION=us-central1
  #     - GCS_BUCKET=gs://md-ml
  #     - GCP_TOPIC=training-requests
  #     - GCP_SUBSCRIPTION=trainer-sub

  model-loader:
    build:
      context: ./docker/model-loader
      dockerfile: Dockerfile
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - GOOGLE_APPLICATION_CREDENTIALS=creds.json
      - PROJECT_ID=md-wbeebe-0808-example-apps
      - REGION=us-central1
      - GCS_BUCKET=gs://md-ml
  model-server:
    platform: linux/amd64
    build:
      context: ./model-server
      dockerfile: Dockerfile
    ports:
    - 6000:5000
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - GOOGLE_APPLICATION_CREDENTIALS=creds.json
      - PROJECT_ID=md-wbeebe-0808-example-apps
      - REGION=us-central1
      - GCS_BUCKET=gs://md-ml
    volumes:
      - model_cache:/root/.cache/huggingface:delegated
  kflow:
    build:
      context: ./kflow
      dockerfile: Dockerfile
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      - GOOGLE_APPLICATION_CREDENTIALS=creds.json
      - PROJECT_ID=md-wbeebe-0808-example-apps
      - REGION=us-central1
      - GCS_BUCKET=gs://md-ml
    volumes:
      - ./creds.json:/creds.json
      - ./kflow/components:/os-shared:default

  gcloud:
    image: google/cloud-sdk:latest
    volumes:
      - ./creds.json:/creds.json
      - ./gcloud-vol:/root/gcloud-vol
    command: >
      bash -c "
      mkdir -p /root/gcloud-vol/job-1668492845 &&
      gcloud auth activate-service-account --key-file=/creds.json &&
      gcloud config set project md-wbeebe-0808-example-apps &&
      gsutil ls gs://md-ml &&
      gsutil -m cp -r \
        "gs://md-ml/job-1668492845/feature_extractor" \
        "gs://md-ml/job-1668492845/img_out" \
        "gs://md-ml/job-1668492845/learned_embeds.bin" \
        "gs://md-ml/job-1668492845/model_index.json" \
        "gs://md-ml/job-1668492845/safety_checker" \
        "gs://md-ml/job-1668492845/scheduler" \
        "gs://md-ml/job-1668492845/text_encoder" \
        "gs://md-ml/job-1668492845/tokenizer" \
        "gs://md-ml/job-1668492845/unet" \
        "gs://md-ml/job-1668492845/vae" \
        /root/gcloud-vol/job-1668492845
      "
